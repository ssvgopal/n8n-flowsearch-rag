{
  "meta": {
    "instanceId": "408f9fb9940c3cb18ffdef0e0150fe342d6e655c3a9fac21f0f644e8bedabcd9",
    "templateCredsSetupCompleted": true
  },
  "nodes": [
    {
      "id": "f8831a38-92ef-44e5-99dd-0f410e9c0883",
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "position": [
        440,
        260
      ],
      "parameters": {
        "options": {},
        "aggregate": "aggregateAllItemData"
      },
      "typeVersion": 1
    },
    {
      "id": "7c51c3f5-3d2f-4d7d-8fd8-30641b1b9516",
      "name": "Github Models",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        240,
        260
      ],
      "parameters": {
        "url": "https://models.github.ai/catalog/models",
        "options": {
          "redirect": {
            "redirect": {}
          }
        },
        "sendHeaders": true,
        "authentication": "predefinedCredentialType",
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github+json"
            },
            {
              "name": "X-GitHub-Api-Version",
              "value": "2022-11-28"
            }
          ]
        },
        "nodeCredentialType": "githubApi"
      },
      "credentials": {
        "githubApi": {
          "id": "kA70YRmLeHDqZbXA",
          "name": "GitHub account"
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "c9602915-e903-4891-b131-68b3190f637b",
      "name": "Github Chat Completions",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1120,
        320
      ],
      "parameters": {
        "url": "https://models.github.ai/inference/chat/completions",
        "method": "POST",
        "options": {
          "redirect": {
            "redirect": {}
          }
        },
        "jsonBody": "={{\n{\n  model: $json.body.model,\n  messages: $json.body.messages,\n  stream: $json.body.stream\n}\n}}",
        "sendBody": true,
        "sendHeaders": true,
        "specifyBody": "json",
        "authentication": "predefinedCredentialType",
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github+json"
            },
            {
              "name": "X-GitHub-Api-Version",
              "value": "2022-11-28"
            }
          ]
        },
        "nodeCredentialType": "githubApi"
      },
      "credentials": {
        "githubApi": {
          "id": "kA70YRmLeHDqZbXA",
          "name": "GitHub account"
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "ccdfc4f2-53dd-409b-9887-6e191374e23c",
      "name": "n8n Webhooks",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        320,
        -160
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "openai/gpt-4o-mini",
          "cachedResultName": "openai/gpt-4o-mini"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "8VVdMPbWsLxTlgC0",
          "name": "n8n-router"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "29ed818b-fb54-4b55-b5ac-1d5220222558",
      "name": "Chat Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        1540,
        400
      ],
      "parameters": {
        "options": {},
        "respondWith": "json",
        "responseBody": "={{ $json }}"
      },
      "typeVersion": 1.2
    },
    {
      "id": "3c36a5c8-28da-4656-aa9d-8593926b3e77",
      "name": "Models Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        640,
        260
      ],
      "parameters": {
        "options": {},
        "respondWith": "json",
        "responseBody": "={{\n({\n  \"object\": \"list\",\n  \"data\":  $json.data.map(item => ({\n    \"id\": item.id,\n    \"object\": \"model\",\n    \"created\": 1733945430,\n    \"owned_by\": \"system\"\n  }))\n})\n}}"
      },
      "executeOnce": false,
      "typeVersion": 1.2
    },
    {
      "id": "3c1efb37-c04c-4426-acde-690dbaf54183",
      "name": "Powered By Github Models",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        240,
        -340
      ],
      "parameters": {},
      "typeVersion": 1.6
    },
    {
      "id": "704e5aae-bda3-4238-b770-f3a1d2732311",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        40,
        -340
      ],
      "webhookId": "6ec7783c-8f47-4fdf-9838-7846b1da4bfa",
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.1
    },
    {
      "id": "ed87f51d-c2bd-43c4-aabb-4f92b12b82f3",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        560,
        -240
      ],
      "parameters": {
        "color": 5,
        "width": 520,
        "height": 220,
        "content": "### LLM Models via N8N Webhooks\n1. Create a new OpenAI Credential and call it \"n8n-webhook\"\n2. Enter API key as anything you like eg. \"12345\"\n3. Enter Base URL as \"https://<your_n8n_url>/webhook/github-models\"\n4. Activate your workflow! This only really works with the production webhook URL.\n\nFeel free to change the names to whatever you want, just make sure the LLM node is able to reach it!"
      },
      "typeVersion": 1
    },
    {
      "id": "c28b03cb-bd1b-41d5-ba1b-486a099afb92",
      "name": "GET models",
      "type": "n8n-nodes-base.webhook",
      "position": [
        40,
        260
      ],
      "webhookId": "f88b9992-b7b9-4ab5-829c-7b89e9cc4775",
      "parameters": {
        "path": "github-models/models",
        "options": {},
        "responseMode": "responseNode"
      },
      "typeVersion": 2
    },
    {
      "id": "02cb7e26-f992-4444-a886-dcaea1dbb63c",
      "name": "POST ChatCompletions",
      "type": "n8n-nodes-base.webhook",
      "position": [
        920,
        320
      ],
      "webhookId": "e8c56164-1825-4ac4-9c23-d209f4907458",
      "parameters": {
        "path": "github-models/chat/completions",
        "options": {},
        "httpMethod": "POST",
        "responseMode": "responseNode"
      },
      "typeVersion": 2
    },
    {
      "id": "be0e06be-2b0d-4167-ad70-84d188f5ca68",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -20,
        -560
      ],
      "parameters": {
        "color": 7,
        "width": 680,
        "height": 580,
        "content": "## 1. Create a New Custom OpenAI Credential\n[Learn more about OpenAI Credentials](https://docs.n8n.io/integrations/builtin/credentials/openai/)\n\nTo use Github Models with our existing n8n nodes, one approach is to mimic an openAI compatible API connected through the OpenAI model subnode. Sounds complicated but don't worry, this template shows you how! The first step is to setup a new OpenAI credential so that we can change the Base URL."
      },
      "typeVersion": 1
    },
    {
      "id": "855c24f5-0758-4344-b780-523383b51de1",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -20,
        60
      ],
      "parameters": {
        "color": 7,
        "width": 840,
        "height": 420,
        "content": "## 2. Listing All Available Models \n[Read more about the Webhook Trigger node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.webhook/)\n\nOur first endpoint is for listing all models. The Github Models API how we can do this but the response requires some re-mapping to make it compatible with our LLM node."
      },
      "typeVersion": 1
    },
    {
      "id": "d5f0446d-2e59-47ee-a442-f66490d8759d",
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        840,
        60
      ],
      "parameters": {
        "color": 7,
        "width": 920,
        "height": 540,
        "content": "## 3. Request a Chat Completion \n[Read more about the HTTP Request node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest)\n\nOur second endpoint is for executing a chat completion. Note that depending on if you have connected with an agent, the response expected is a \"stream\" and returned data needs to be of type `text/plain`."
      },
      "typeVersion": 1
    },
    {
      "id": "e8a13b04-fd51-4031-90f3-7088871e6dfd",
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -520,
        -560
      ],
      "parameters": {
        "width": 420,
        "height": 1280,
        "content": "## Try It Out!\n### This n8n template shows you how to connect [Github's Free Models](https://docs.github.com/en/github-models) to your existing n8n AI workflows.\n\nWhilst it is possible to use HTTP nodes to access Github Models, The aim of this template is to use it with existing n8n LLM nodes - saves the trouble of refactoring!\n\nPlease note, Github states their model APIs are not intended for production usage! If you need higher rate limits, you'll need to use a paid service.\n\n### How it works\n* The approach builds a custom OpenAI compatible API around the Github Models API - all done in n8n!\n* First, we attach an OpenAI subnode to our LLM node and configure a new OpenAI credential.\n* Within this new OpenAI credential, we change the \"Base URL\" to point at a n8n webhook we've prepared as part of this template.\n* Next, we create 2 webhooks which the LLM node will now attempt to connect with: \"models\" and \"chat completion\".\n* The \"models\" webhook simply calls the Github Model's \"list all models\" endpoint and remaps the response to be compatible with our LLM node.\n* The \"Chat Completion\" webhook does a similar task with Github's Chat Completion endpoint.\n\n### How to use\n* Once connected, just open chat and ask away!\n* Any LLM or AI agent node connected with this custom LLM subnode will send requests to the Github Models API. Allowing your to try out a range of SOTA models for free.\n\n### Requirements\n* Github account and credentials for access to Models. If you've used the Github node previously, you can reuse this credential for this template.\n\n### Customising this workflow\n* This template is just an example. Use the custom OpenAI credential for your other workflows to test Github models.\n\n### References\n* [https://docs.github.com/en/github-models/prototyping-with-ai-models](https://docs.github.com/en/github-models/prototyping-with-ai-models)\n* [https://docs.github.com/en/github-models](https://docs.github.com/en/github-models)\n\n### Need Help?\nJoin the [Discord](https://discord.com/invite/XPKeKXeB7d) or ask in the [Forum](https://community.n8n.io/)!\n\nHappy Hacking!"
      },
      "typeVersion": 1
    },
    {
      "id": "2a75f35d-695f-425d-8b8e-425c9075c702",
      "name": "Is Agent?",
      "type": "n8n-nodes-base.if",
      "position": [
        1320,
        320
      ],
      "parameters": {
        "options": {},
        "conditions": {
          "options": {
            "version": 2,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "213702bf-d5c2-4a8a-b5c8-e55f804e4496",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              },
              "leftValue": "={{ $('POST ChatCompletions').first().json.body.stream }}",
              "rightValue": ""
            }
          ]
        }
      },
      "typeVersion": 2.2
    },
    {
      "id": "31e0325d-ef82-40af-862b-9dcffbf650e6",
      "name": "Agent Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        1540,
        240
      ],
      "parameters": {
        "options": {},
        "respondWith": "text",
        "responseBody": "={{ $json.data }}"
      },
      "typeVersion": 1.2
    }
  ],
  "pinData": {},
  "connections": {
    "Aggregate": {
      "main": [
        [
          {
            "node": "Models Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Agent?": {
      "main": [
        [
          {
            "node": "Agent Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Chat Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GET models": {
      "main": [
        [
          {
            "node": "Github Models",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "n8n Webhooks": {
      "ai_languageModel": [
        [
          {
            "node": "Powered By Github Models",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Github Models": {
      "main": [
        [
          {
            "node": "Aggregate",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "POST ChatCompletions": {
      "main": [
        [
          {
            "node": "Github Chat Completions",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Github Chat Completions": {
      "main": [
        [
          {
            "node": "Is Agent?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Powered By Github Models",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}